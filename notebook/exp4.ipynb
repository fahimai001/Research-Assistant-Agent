{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import base64\n",
    "import sqlite3\n",
    "import tempfile\n",
    "from typing import List, Optional, Dict, Any\n",
    "from datetime import datetime\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "# Third-party imports\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from IPython.display import Markdown, display, HTML\n",
    "import PyPDF2 \n",
    "import docx  \n",
    "from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "# Initialize Gemini model\n",
    "gemini_model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    google_api_key=GEMINI_API_KEY,\n",
    "    temperature=0.7,\n",
    "    max_tokens=4000,\n",
    ")\n",
    "\n",
    "# Create output schema for topic recommendations\n",
    "class RecommendedTopic(BaseModel):\n",
    "    topic: str = Field(description=\"The name of the recommended topic\")\n",
    "    description: str = Field(description=\"A brief description of why this topic is relevant\")\n",
    "    resource_url: str = Field(description=\"A relevant resource URL for this topic\")\n",
    "\n",
    "class TopicRecommendations(BaseModel):\n",
    "    recommendations: List[RecommendedTopic] = Field(description=\"List of recommended related topics\")\n",
    "\n",
    "# Create output schema for paper recommendations\n",
    "class RecommendedPaper(BaseModel):\n",
    "    title: str = Field(description=\"The title of the recommended research paper\")\n",
    "    authors: str = Field(description=\"The authors of the paper\")\n",
    "    year: str = Field(description=\"Publication year\")\n",
    "    description: str = Field(description=\"Brief description of relevance to the original paper\")\n",
    "    paper_url: str = Field(description=\"URL to access this paper\", default=\"\")\n",
    "\n",
    "class PaperRecommendations(BaseModel):\n",
    "    recommendations: List[RecommendedPaper] = Field(description=\"List of recommended related papers\")\n",
    "\n",
    "# Create prompt templates\n",
    "report_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are an AI research assistant. Create a comprehensive, detailed report on the following topic:\n",
    "    \n",
    "    Topic: {topic}\n",
    "    \n",
    "    Your report should include:\n",
    "    1. Introduction to the topic\n",
    "    2. Key concepts and definitions\n",
    "    3. Historical context and development\n",
    "    4. Current state and applications\n",
    "    5. Future directions and potential developments\n",
    "    6. Conclusion\n",
    "    \n",
    "    Format your report with clear markdown headings and subheadings. Use proper markdown formatting for emphasis, lists, and other elements.\n",
    "    Make sure to provide in-depth analysis.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "recommendation_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Based on the topic: {topic}\n",
    "    \n",
    "    Generate 5 relevant related topics that the user might be interested in researching next.\n",
    "    For each recommendation, provide:\n",
    "    1. The topic name\n",
    "    2. A brief 1-2 sentence description of why it's relevant\n",
    "    3. A relevant resource URL that would contain valuable information about this topic\n",
    "    \n",
    "    Your response must be formatted as a valid JSON object that matches this structure:\n",
    "    {\n",
    "        \"recommendations\": [\n",
    "            {\n",
    "                \"topic\": \"Topic Name\",\n",
    "                \"description\": \"Brief description of relevance\",\n",
    "                \"resource_url\": \"https://example.com/relevant-page\"\n",
    "            },\n",
    "            ...\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    Use reputable sources for your resource URLs. While you can't verify if the exact URLs exist,\n",
    "    make them realistic and likely to contain quality information.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "paper_summary_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are an AI research assistant. Create a concise but comprehensive summary of the following research paper:\n",
    "    \n",
    "    Paper content: {paper_content}\n",
    "    \n",
    "    Your summary should include:\n",
    "    1. Main objective of the research\n",
    "    2. Methodology used\n",
    "    3. Key findings and results\n",
    "    4. Main conclusions and implications\n",
    "    5. Limitations (if mentioned)\n",
    "    \n",
    "    Format your summary with clear markdown headings and keep it concise yet informative.\n",
    "    Focus on the most important aspects of the paper.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "paper_recommendation_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Based on the following research paper:\n",
    "    \n",
    "    Paper content: {paper_content}\n",
    "    \n",
    "    Generate 5 relevant related research papers that the user might be interested in reading next.\n",
    "    These should be real papers that likely exist in the academic literature.\n",
    "    \n",
    "    For each recommendation, provide:\n",
    "    1. The paper title (use the actual title of a real paper if you know it)\n",
    "    2. The authors (use \"et al.\" for multiple authors after the first)\n",
    "    3. Publication year (estimate if necessary)\n",
    "    4. A brief description of why it's relevant to the original paper\n",
    "    5. A URL where the paper might be found - THIS IS CRITICAL. \n",
    "    \n",
    "    For URLs, use specific links from:\n",
    "    - Google Scholar (https://scholar.google.com/scholar?q=PAPER_TITLE)\n",
    "    - arXiv (https://arxiv.org/search/?query=PAPER_TITLE)\n",
    "    - ResearchGate (https://www.researchgate.net/search.Search.html?query=PAPER_TITLE)\n",
    "    - ACM Digital Library (https://dl.acm.org/action/doSearch?AllField=PAPER_TITLE)\n",
    "    - IEEE Xplore (https://ieeexplore.ieee.org/search/searchresult.jsp?queryText=PAPER_TITLE)\n",
    "    \n",
    "    Replace PAPER_TITLE with URL-encoded paper title in these templates. Make sure EVERY recommendation has a working URL.\n",
    "    \n",
    "    Your response must be formatted as a valid JSON object that matches this structure:\n",
    "    {{\n",
    "        \"recommendations\": [\n",
    "            {{\n",
    "                \"title\": \"Paper Title\",\n",
    "                \"authors\": \"Author names\",\n",
    "                \"year\": \"Publication year\",\n",
    "                \"description\": \"Brief description of relevance\",\n",
    "                \"paper_url\": \"https://example.com/paper-link\"\n",
    "            }},\n",
    "            ...\n",
    "        ]\n",
    "    }}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Create chains\n",
    "report_chain = (\n",
    "    {\"topic\": RunnablePassthrough()}\n",
    "    | report_prompt\n",
    "    | gemini_model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "recommendation_chain = (\n",
    "    {\"topic\": RunnablePassthrough()}\n",
    "    | recommendation_prompt\n",
    "    | gemini_model\n",
    "    | JsonOutputParser(pydantic_object=TopicRecommendations)\n",
    ")\n",
    "\n",
    "paper_summary_chain = (\n",
    "    {\"paper_content\": RunnablePassthrough()}\n",
    "    | paper_summary_prompt\n",
    "    | gemini_model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "paper_recommendation_chain = (\n",
    "    {\"paper_content\": RunnablePassthrough()}\n",
    "    | paper_recommendation_prompt\n",
    "    | gemini_model\n",
    "    | JsonOutputParser(pydantic_object=PaperRecommendations)\n",
    ")\n",
    "\n",
    "# --------------------- Database Functions ---------------------\n",
    "def initialize_database(db_path: str = \"research_papers.db\"):\n",
    "    \"\"\"Initialize SQLite database for storing papers\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS papers (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            filename TEXT NOT NULL,\n",
    "            content TEXT NOT NULL,\n",
    "            file_type TEXT NOT NULL,\n",
    "            upload_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "            summary TEXT\n",
    "        )\n",
    "    ''')\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def save_file_to_database(filename: str, content: str, file_type: str, db_path: str = \"research_papers.db\"):\n",
    "    \"\"\"Save file content to SQLite database\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\n",
    "        \"INSERT INTO papers (filename, content, file_type) VALUES (?, ?, ?)\",\n",
    "        (filename, content, file_type)\n",
    "    )\n",
    "    paper_id = cursor.lastrowid\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    return paper_id\n",
    "\n",
    "def save_summary_to_database(paper_id: int, summary: str, db_path: str = \"research_papers.db\"):\n",
    "    \"\"\"Save paper summary to database\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\n",
    "        \"UPDATE papers SET summary = ? WHERE id = ?\",\n",
    "        (summary, paper_id)\n",
    "    )\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def get_paper_from_database(paper_id: int, db_path: str = \"research_papers.db\"):\n",
    "    \"\"\"Retrieve paper content from database\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT filename, content, file_type, summary FROM papers WHERE id = ?\", (paper_id,))\n",
    "    result = cursor.fetchone()\n",
    "    conn.close()\n",
    "    if result:\n",
    "        return {\n",
    "            \"filename\": result[0],\n",
    "            \"content\": result[1],\n",
    "            \"file_type\": result[2],\n",
    "            \"summary\": result[3]\n",
    "        }\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# --------------------- Text Extraction Functions ---------------------\n",
    "def extract_text_from_pdf(file_path: str) -> str:\n",
    "    \"\"\"Extract text content from a PDF file\"\"\"\n",
    "    try:\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        documents = loader.load()\n",
    "        text_content = \"\\n\\n\".join([doc.page_content for doc in documents])\n",
    "        return text_content\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from PDF: {str(e)}\")\n",
    "        # Fallback method\n",
    "        text = \"\"\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "            for page in pdf_reader.pages:\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "        return text\n",
    "\n",
    "def extract_text_from_docx(file_path: str) -> str:\n",
    "    \"\"\"Extract text content from a DOCX file\"\"\"\n",
    "    try:\n",
    "        loader = Docx2txtLoader(file_path)\n",
    "        documents = loader.load()\n",
    "        text_content = \"\\n\\n\".join([doc.page_content for doc in documents])\n",
    "        return text_content\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from DOCX: {str(e)}\")\n",
    "        # Fallback method\n",
    "        doc = docx.Document(file_path)\n",
    "        text = \"\"\n",
    "        for paragraph in doc.paragraphs:\n",
    "            text += paragraph.text + \"\\n\"\n",
    "        return text\n",
    "\n",
    "# --------------------- Report and Recommendation Functions ---------------------\n",
    "def generate_report(topic: str) -> str:\n",
    "    \"\"\"Generate a detailed report on the given topic\"\"\"\n",
    "    return report_chain.invoke(topic)\n",
    "\n",
    "def generate_recommendations(topic: str) -> str:\n",
    "    \"\"\"Generate relevant topic recommendations using Gemini API\"\"\"\n",
    "    try:\n",
    "        recommendations_data = recommendation_chain.invoke(topic)\n",
    "        formatted_recommendations = \"# Related Topics You May Be Interested In\\n\\n\"\n",
    "        for i, rec in enumerate(recommendations_data.recommendations, 1):\n",
    "            formatted_recommendations += f\"## {i}. {rec.topic}\\n\"\n",
    "            formatted_recommendations += f\"{rec.description}\\n\"\n",
    "            formatted_recommendations += f\"[Learn more]({rec.resource_url})\\n\\n\"\n",
    "        return formatted_recommendations\n",
    "    except Exception as e:\n",
    "        backup_prompt = ChatPromptTemplate.from_template(\n",
    "            \"\"\"\n",
    "            Based on the topic: {topic}\n",
    "            \n",
    "            Provide 5 relevant related topics that the user might be interested in researching next.\n",
    "            For each recommendation, provide:\n",
    "            1. The topic name\n",
    "            2. A brief description of why it's relevant\n",
    "            3. A relevant resource link\n",
    "            \n",
    "            Format your response as a markdown list.\n",
    "            \"\"\"\n",
    "        )\n",
    "        backup_chain = backup_prompt | gemini_model | StrOutputParser()\n",
    "        return backup_chain.invoke({\"topic\": topic})\n",
    "\n",
    "def create_full_report(topic: str, report_content: str, recommendations_content: str) -> str:\n",
    "    \"\"\"Create a full markdown report combining the report and recommendations\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    full_report = f\"\"\"\n",
    "# Research Report: {topic}\n",
    "\n",
    "*Generated on: {timestamp}*\n",
    "\n",
    "---\n",
    "\n",
    "{report_content}\n",
    "\n",
    "---\n",
    "\n",
    "{recommendations_content}\n",
    "\n",
    "---\n",
    "\n",
    "*This report was generated by AI Research Assistant using Gemini API*\n",
    "\"\"\"\n",
    "    return full_report\n",
    "\n",
    "def create_full_paper_analysis(filename: str, summary_content: str, recommendations_content: str) -> str:\n",
    "    \"\"\"Create a full markdown report for paper analysis\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    full_report = f\"\"\"\n",
    "# Research Paper Analysis: {filename}\n",
    "\n",
    "*Generated on: {timestamp}*\n",
    "\n",
    "---\n",
    "\n",
    "## Paper Summary\n",
    "\n",
    "{summary_content}\n",
    "\n",
    "---\n",
    "\n",
    "{recommendations_content}\n",
    "\n",
    "---\n",
    "\n",
    "*This analysis was generated by AI Research Assistant using Gemini API*\n",
    "\"\"\"\n",
    "    return full_report\n",
    "\n",
    "# --------------------- File and Display Functions ---------------------\n",
    "def sanitize_filename(filename: str) -> str:\n",
    "    \"\"\"Convert a string to a valid filename\"\"\"\n",
    "    return re.sub(r'[\\\\/*?:\"<>|]', \"_\", filename)\n",
    "\n",
    "def save_markdown_file(topic: str, content: str) -> str:\n",
    "    \"\"\"Save content to a markdown file\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    safe_topic = sanitize_filename(topic)\n",
    "    filename = f\"research_{safe_topic}_{timestamp}.md\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "    return filename\n",
    "\n",
    "def display_markdown(content: str, use_markdown_display: bool = True):\n",
    "    \"\"\"Display content as rendered markdown if in IPython environment\"\"\"\n",
    "    try:\n",
    "        if use_markdown_display:\n",
    "            display(Markdown(content))\n",
    "        else:\n",
    "            print(content)\n",
    "    except:\n",
    "        print(content)\n",
    "\n",
    "# --------------------- Paper Processing Functions ---------------------\n",
    "def process_research_paper(file_path: str, original_filename: Optional[str] = None, db_path: str = \"research_papers.db\") -> Dict[str, Any]:\n",
    "    \"\"\"Process a research paper file (PDF or DOCX)\"\"\"\n",
    "    if not original_filename:\n",
    "        original_filename = os.path.basename(file_path)\n",
    "    file_extension = os.path.splitext(original_filename)[1].lower()\n",
    "    if file_extension == '.pdf':\n",
    "        text_content = extract_text_from_pdf(file_path)\n",
    "        file_type = 'pdf'\n",
    "    elif file_extension in ['.docx', '.doc']:\n",
    "        text_content = extract_text_from_docx(file_path)\n",
    "        file_type = 'docx'\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {file_extension}\")\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=12000,\n",
    "        chunk_overlap=2000\n",
    "    )\n",
    "    chunks = text_splitter.split_text(text_content)\n",
    "    processing_text = chunks[0] if len(chunks) > 0 else text_content\n",
    "    paper_id = save_file_to_database(original_filename, text_content, file_type, db_path=db_path)\n",
    "    try:\n",
    "        print(\"- Generating research paper summary...\")\n",
    "        summary = paper_summary_chain.invoke(processing_text)\n",
    "        save_summary_to_database(paper_id, summary, db_path=db_path)\n",
    "        print(\"- Finding related research papers with access links...\")\n",
    "        try:\n",
    "            recommendations_data = paper_recommendation_chain.invoke(processing_text)\n",
    "            recs = recommendations_data.get(\"recommendations\", [])\n",
    "            formatted_recommendations = \"# Related Research Papers You May Be Interested In\\n\\n\"\n",
    "            for i, rec in enumerate(recs, 1):\n",
    "                formatted_recommendations += f\"## {i}. {rec['title']} ({rec['year']})\\n\"\n",
    "                formatted_recommendations += f\"**Authors:** {rec['authors']}\\n\\n\"\n",
    "                formatted_recommendations += f\"{rec['description']}\\n\"\n",
    "                paper_url = rec.get(\"paper_url\", \"\").strip()\n",
    "                if not paper_url:\n",
    "                    encoded_title = re.sub(r'\\s+', '+', rec['title'])\n",
    "                    paper_url = f\"https://scholar.google.com/scholar?q={encoded_title}\"\n",
    "                formatted_recommendations += f\"[Access Paper]({paper_url})\\n\\n\"\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating paper recommendations: {str(e)}\")\n",
    "            backup_prompt = ChatPromptTemplate.from_template(\n",
    "                \"\"\"\n",
    "                Based on the following research paper content:\n",
    "                \n",
    "                {paper_content}\n",
    "                \n",
    "                Provide 5 relevant related research papers that might be of interest.\n",
    "                For each paper, include:\n",
    "                1. Title (a real paper title if possible)\n",
    "                2. Authors\n",
    "                3. Year\n",
    "                4. Brief description of relevance\n",
    "                5. MOST IMPORTANTLY: A direct URL to access the paper (use Google Scholar, arXiv, or ResearchGate)\n",
    "                \n",
    "                Format your response in markdown with clear headings and clickable links.\n",
    "                Make sure every recommendation has a working URL.\n",
    "                \"\"\"\n",
    "            )\n",
    "            backup_chain = backup_prompt | gemini_model | StrOutputParser()\n",
    "            formatted_recommendations = backup_chain.invoke({\"paper_content\": processing_text})\n",
    "        return {\n",
    "            \"paper_id\": paper_id,\n",
    "            \"filename\": original_filename,\n",
    "            \"summary\": summary,\n",
    "            \"recommendations\": formatted_recommendations,\n",
    "            \"success\": True\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing research paper: {str(e)}\")\n",
    "        return {\n",
    "            \"paper_id\": paper_id,\n",
    "            \"filename\": original_filename,\n",
    "            \"error\": str(e),\n",
    "            \"success\": False\n",
    "        }\n",
    "\n",
    "# --------------------- Main Task Functions ---------------------\n",
    "def run_research(topic: str, use_markdown_display: bool = True, db_path: str = \"research_papers.db\") -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"Perform research on a specific topic\"\"\"\n",
    "    if not topic.strip():\n",
    "        print(\"Please enter a valid topic.\")\n",
    "        return\n",
    "    print(f\"\\nResearching '{topic}'... This may take a moment.\")\n",
    "    try:\n",
    "        initialize_database(db_path)\n",
    "        print(\"- Generating detailed report...\")\n",
    "        report = generate_report(topic)\n",
    "        print(\"- Finding related topics...\")\n",
    "        recommendations = generate_recommendations(topic)\n",
    "        full_report = create_full_report(topic, report, recommendations)\n",
    "        filename = save_markdown_file(topic, full_report)\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"RESEARCH REPORT: {topic.upper()}\")\n",
    "        print(\"=\"*50 + \"\\n\")\n",
    "        display_markdown(report, use_markdown_display)\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"RECOMMENDED RELATED TOPICS\")\n",
    "        print(\"=\"*50 + \"\\n\")\n",
    "        display_markdown(recommendations, use_markdown_display)\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"Full report saved to: {filename}\")\n",
    "        print(\"=\"*50)\n",
    "        return {\n",
    "            \"report\": report,\n",
    "            \"recommendations\": recommendations,\n",
    "            \"full_report\": full_report,\n",
    "            \"filename\": filename\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def run_paper_analysis(file_path: str, original_filename: Optional[str] = None, use_markdown_display: bool = True, db_path: str = \"research_papers.db\") -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"Analyze a research paper file\"\"\"\n",
    "    try:\n",
    "        initialize_database(db_path)\n",
    "        result = process_research_paper(file_path, original_filename, db_path=db_path)\n",
    "        if result[\"success\"]:\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(f\"PAPER ANALYSIS: {result['filename']}\")\n",
    "            print(\"=\"*50 + \"\\n\")\n",
    "            display_markdown(result[\"summary\"], use_markdown_display)\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(\"RECOMMENDED RELATED PAPERS\")\n",
    "            print(\"=\"*50 + \"\\n\")\n",
    "            display_markdown(result[\"recommendations\"], use_markdown_display)\n",
    "            full_analysis = create_full_paper_analysis(\n",
    "                result[\"filename\"],\n",
    "                result[\"summary\"],\n",
    "                result[\"recommendations\"]\n",
    "            )\n",
    "            analysis_filename = save_markdown_file(f\"paper_analysis_{sanitize_filename(result['filename'])}\", full_analysis)\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(f\"Full analysis saved to: {analysis_filename}\")\n",
    "            print(\"=\"*50)\n",
    "            return {\n",
    "                \"summary\": result[\"summary\"],\n",
    "                \"recommendations\": result[\"recommendations\"],\n",
    "                \"full_analysis\": full_analysis,\n",
    "                \"filename\": analysis_filename\n",
    "            }\n",
    "        else:\n",
    "            print(f\"Failed to process paper: {result.get('error', 'Unknown error')}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while analyzing the paper: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def run_web_interface(use_markdown_display: bool = True, db_path: str = \"research_papers.db\"):\n",
    "    \"\"\"Run a web interface using IPython widgets\"\"\"\n",
    "    try:\n",
    "        from ipywidgets import widgets\n",
    "        from IPython.display import display, clear_output\n",
    "        output = widgets.Output()\n",
    "        topic_input = widgets.Text(description='Topic:', placeholder='Enter research topic')\n",
    "        search_button = widgets.Button(description='Research Topic')\n",
    "        file_upload = widgets.FileUpload(\n",
    "            accept='.pdf,.docx,.doc',\n",
    "            multiple=False,\n",
    "            description='Upload Paper'\n",
    "        )\n",
    "        analyze_button = widgets.Button(description='Analyze Paper')\n",
    "        def on_search_click(b):\n",
    "            with output:\n",
    "                clear_output()\n",
    "                run_research(topic_input.value, use_markdown_display, db_path)\n",
    "        def on_analyze_click(b):\n",
    "            with output:\n",
    "                clear_output()\n",
    "                if not file_upload.value:\n",
    "                    print(\"Please upload a research paper file (PDF or DOCX).\")\n",
    "                    return\n",
    "                file_data = next(iter(file_upload.value.values()))\n",
    "                file_name = next(iter(file_upload.value.keys()))\n",
    "                with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(file_name)[1]) as temp_file:\n",
    "                    temp_file.write(file_data['content'])\n",
    "                    temp_path = temp_file.name\n",
    "                try:\n",
    "                    run_paper_analysis(temp_path, file_name, use_markdown_display, db_path)\n",
    "                finally:\n",
    "                    os.unlink(temp_path)\n",
    "        search_button.on_click(on_search_click)\n",
    "        analyze_button.on_click(on_analyze_click)\n",
    "        tab1 = widgets.VBox([topic_input, search_button])\n",
    "        tab2 = widgets.VBox([file_upload, analyze_button])\n",
    "        tabs = widgets.Tab(children=[tab1, tab2])\n",
    "        tabs.set_title(0, 'Topic Research')\n",
    "        tabs.set_title(1, 'Paper Analysis')\n",
    "        display(tabs)\n",
    "        display(output)\n",
    "    except ImportError:\n",
    "        print(\"This function requires ipywidgets. Please install with: pip install ipywidgets\")\n",
    "        print(\"Running in command line mode instead.\")\n",
    "        run()\n",
    "\n",
    "# --------------------- Helper Functions for Jupyter ---------------------\n",
    "def research_topic(topic: str):\n",
    "    \"\"\"Helper function to research a topic directly from a Jupyter notebook\"\"\"\n",
    "    return run_research(topic, use_markdown_display=True)\n",
    "\n",
    "def analyze_paper(file_path: str):\n",
    "    \"\"\"Helper function to analyze a paper directly from a Jupyter notebook\"\"\"\n",
    "    return run_paper_analysis(file_path, use_markdown_display=True)\n",
    "\n",
    "# --------------------- Main Loop ---------------------\n",
    "def run():\n",
    "    \"\"\"Main agent loop with support for both topic research and paper analysis\"\"\"\n",
    "    initialize_database()\n",
    "    print(\"üîç AI Research Assistant Agent üîç\")\n",
    "    print(\"--------------------------------\")\n",
    "    print(\"I can help you research topics and analyze research papers.\")\n",
    "    while True:\n",
    "        print(\"\\nWhat would you like to do?\")\n",
    "        print(\"1. Research a topic\")\n",
    "        print(\"2. Analyze a research paper\")\n",
    "        print(\"3. Exit\")\n",
    "        choice = input(\"Enter your choice (1-3): \")\n",
    "        if choice == '1':\n",
    "            topic = input(\"\\nWhat topic would you like to research? \")\n",
    "            if topic.strip():\n",
    "                run_research(topic)\n",
    "            else:\n",
    "                print(\"Please enter a valid topic.\")\n",
    "        elif choice == '2':\n",
    "            file_path = input(\"\\nEnter the path to the research paper file (PDF or DOCX): \")\n",
    "            if os.path.exists(file_path):\n",
    "                run_paper_analysis(file_path)\n",
    "            else:\n",
    "                print(f\"File not found: {file_path}\")\n",
    "        elif choice == '3':\n",
    "            print(\"Thank you for using the AI Research Assistant. Goodbye!\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid choice. Please enter 1, 2, or 3.\")\n",
    "\n",
    "# --------------------- Execution ---------------------\n",
    "if __name__ == \"__main__\":\n",
    "    run()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
